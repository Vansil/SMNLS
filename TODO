TODO:
zie ook Google Docs: https://docs.google.com/document/d/1MyKtpJo-vQjtpHbITRMSR5xyMoxn5zrZyDGeWYsIbmc/edit

Other:
- Shared LISA account (lgpu0219, Bjachan69)


WEEK 5

TODO:
Finish and train a model (whatever we'll finish this week will be the main topic of our analysis)
- POS task (dataset available?)
- Disambiguation task
- Sequential labelling task
- Architectures
- Training schemes

- Quantitative analysis
- WiC: set to eval() mode


Silvan
- disamb. train/dev/test split

Bjarne
- disamb task

Tycho









--------------------------------------------
WEEK 4
Silvan:
- Evaluate loaded model
- Mail Katia over POS dataset
- Baseline test: ELMo


Bjarne:
- Dataloader: disambig
- Sequential task





--------------------------------------------
WEEK 3
Bjarne:
- add VUA to get_data.sh
- test Sequential model on VUA
- maak dataloader parallel


Silvan
- general Embedding Module
- Evaluation

Tycho:
- State of the art opzoeken

-------------------------------------------

WEEK2

Evaluation: (TYCHO)
- SentEval
- Word-in-Context
- Extension of TensorBoard metrics, redirecting to the web
    - Gradient norm per layer

Model: 
- Training on Gao's sequential metaphor identification task, combined with NLI (BJARNE)
- Pre-trained ELMo vectors (SILVAN)

Experiment:
- Preprocess data (filter GloVe, ...?)
- Make subsets of data -> overfit
- Train at least one model to ok performance (BJARNE)





